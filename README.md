# optimization_decentralized_sgd

This repository is about Decentralized SGD, based on the papers 
1) "A Unified Theory of Decentralized SGD with Changing Topology and Local Updates" Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, Sebastian U. Stich 
2) "Revisiting Gradient Clipping: Stochastic bias and tight convergence guarantees" Anastasia Koloskova, Hadrien Hendrikx, Sebastian U. Stich

We repeate a few experiments from the research and take some our own experiments. 
In folders revisiting_gradient_clipping and Decentralised_SGD you can find the notebooks for those papers accordingly.

To run all experiments you should run first Decentralised_SGD/Topologies/Topology.ipynb with needed number of nodes and then Decentralised_SGD/DSGD.ipynb, revisiting_gradient_clipping/gradient_clipping.ipynb or just download the repository and run the notebooks.